---
icon: simple/apachespark
tags: [Updating]
comments: true
---

# Big Data

##  Spark

QuickStart: <https://spark.apache.org/docs/latest/quick-start.html>

Sparkâ€™s primary abstraction is a distributed collection of items called a Dataset. Datasets can be created from Hadoop InputFormats (such as HDFS files) or by transforming other Datasets. All Datasets in Python are Dataset[Row], and we call it `DataFrame`.

### RDD

Resilient Distributed Dataset (RDD)

Hadoop Distributed File System (HDFS)

### PySpark API

#### sql.Column

A column in a DataFrame.



#### sql.functions.

`from pyspark.sql import functions as sf`

1.   `col`